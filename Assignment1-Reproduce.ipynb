{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** LI XINYAN\n",
    "\n",
    "**EID:** 55670594\n",
    "\n",
    "**Kaggle Team Name:** Saaries98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS5489 - Assignment 1 - Tweet Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final submission\n",
    "In this file, put the code that generates your final Kaggle submission. It will be used to verify that your Kaggle submission is reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import IPython.core.display         \n",
    "# setup output image format (Chrome works best)\n",
    "IPython.core.display.set_matplotlib_formats(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "from scipy import stats\n",
    "import csv\n",
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_data(fname):\n",
    "    txtdata = []\n",
    "    classes = []\n",
    "    topics  = []\n",
    "    with open(fname, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        for row in reader:\n",
    "            # get the text\n",
    "            txtdata.append(row[0])\n",
    "            # get the class (convert to integer)\n",
    "            if len(row)>1:\n",
    "                classes.append(row[1])\n",
    "                topics.append(row[2])\n",
    "    \n",
    "    if (len(classes)>0) and (len(txtdata) != len(classes)):        \n",
    "        raise Exception(\"mismatched length!\")\n",
    "    \n",
    "    return (txtdata, classes, topics)\n",
    "\n",
    "def write_csv_kaggle_sub(fname, Y):\n",
    "    # fname = file name\n",
    "    # Y is a list/array with class entries\n",
    "    \n",
    "    # header\n",
    "    tmp = [['Id', 'Prediction']]\n",
    "    \n",
    "    # add ID numbers for each Y\n",
    "    for (i,y) in enumerate(Y):\n",
    "        tmp2 = [(i+1), y]\n",
    "        tmp.append(tmp2)\n",
    "        \n",
    "    # write CSV file\n",
    "    with open(fname, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2396\n",
      "1028\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "# (if using Kaggle notebooks you need to include the directory path: /kaggle/input/cs5489-2020b-assignment-1/)\n",
    "(traintxt, trainY, traintopic) = read_text_data(\"sanders_tweets_train.txt\")\n",
    "(testtxt, _, _)                = read_text_data(\"sanders_tweets_test.txt\")\n",
    "\n",
    "print(len(traintxt))\n",
    "print(len(testtxt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'neutral' 'positive']\n"
     ]
    }
   ],
   "source": [
    "# write your predictions on the test set\n",
    "classnames = unique(trainY)\n",
    "print(classnames)\n",
    "i = random.randint(len(classnames), size=len(testtxt))\n",
    "predY = classnames[i]\n",
    "# write_csv_kaggle_sub(\"my_submission.csv\", predY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from afinn import Afinn\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def eva_afinn_score(string):\n",
    "    af = Afinn(emoticons=True)\n",
    "    scr = af.score(string)\n",
    "    return scr\n",
    "\n",
    "def eva_blob_score(string):\n",
    "    scr = TextBlob(string).sentiment.polarity\n",
    "    return scr\n",
    "\n",
    "def add_extra_feature(df, tweet_column):\n",
    "    df['number_of_quote'] = tweet_column.apply(lambda x: (len(re.findall(r'\"', x))/2))\n",
    "    df['number_of_stop'] = tweet_column.apply(lambda x: (len(re.findall(r'.', x))))\n",
    "    df['number_of_exclamation'] = tweet_column.apply(lambda x: (len(re.findall(r'!', x))))\n",
    "    df['number_of_questionmark'] = tweet_column.apply(lambda x: (len(re.findall(r'[?]', x))))\n",
    "    df['number_of_hashtag'] = tweet_column.apply(lambda x: (len(re.findall(r'#', x))))\n",
    "    df['number_of_mention'] = tweet_column.apply(lambda x: (len(re.findall(r'@', x))))\n",
    "    df['number_of_comma'] = tweet_column.apply(lambda x: (len(re.findall(r',', x))))\n",
    "\n",
    "def eva_comp(df, tweet_column):\n",
    "    df['apple'] = tweet_column.apply(lambda x: int('apple' in x))\n",
    "    df['google'] = tweet_column.apply(lambda x: int('google' in x))\n",
    "    df['twitter'] = tweet_column.apply(lambda x: int('twitter' in x))\n",
    "    df['microsoft'] = tweet_column.apply(lambda x: int('microsoft' in x))\n",
    "\n",
    "def clean_str(string):\n",
    "    string = re.sub(\"&lt;3\",\"love\", string)\n",
    "    string = re.sub(\"http://[\\w|./]*\",\"\", string)\n",
    "    string = re.sub(r\"[^A-Za-z]\", \" \", string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def stemming(words):\n",
    "    ps = PorterStemmer()\n",
    "    stem_words = []\n",
    "    for w in words:\n",
    "        w = ps.stem(w)\n",
    "        stem_words.append(w)\n",
    "    return stem_words\n",
    "\n",
    "def word_to_sen(words):\n",
    "    sen = ''\n",
    "    for w in words:\n",
    "        sen = sen + w + ' '\n",
    "    return sen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "c1 = np.array(traintxt)\n",
    "c2 = np.array(traintopic)\n",
    "c3 = np.array(trainY)\n",
    "\n",
    "dix = {\"traintxt\": c1,\n",
    "       \"traintopic\":c2,\n",
    "       \"trainY\":c3}\n",
    "\n",
    "train_data = pd.DataFrame(dix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: 1~3\n",
    "add_extra_feature(train_data, train_data[\"traintxt\"])\n",
    "train_data['affin'] = train_data['traintxt'].apply(eva_afinn_score)\n",
    "train_data['blob'] = train_data['traintxt'].apply(eva_blob_score)\n",
    "\n",
    "# Helper function: 5\n",
    "train_data['traintxt'] = train_data['traintxt'].apply(clean_str)\n",
    "\n",
    "# Helper function: 4\n",
    "eva_comp(train_data, train_data[\"traintxt\"])\n",
    "\n",
    "# Helper function: 6~8\n",
    "train_data[\"traintxt\"] = train_data[\"traintxt\"].apply(tokenize)\n",
    "train_data[\"traintxt\"] = train_data[\"traintxt\"].apply(stemming)\n",
    "train_data[\"traintxt\"] = train_data[\"traintxt\"].apply(word_to_sen)\n",
    "\n",
    "# The tweets length might also be helpeful\n",
    "train_data['length'] =  train_data[\"traintxt\"].apply(lambda x: (len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traintxt</th>\n",
       "      <th>traintopic</th>\n",
       "      <th>trainY</th>\n",
       "      <th>number_of_quote</th>\n",
       "      <th>number_of_stop</th>\n",
       "      <th>number_of_exclamation</th>\n",
       "      <th>number_of_questionmark</th>\n",
       "      <th>number_of_hashtag</th>\n",
       "      <th>number_of_mention</th>\n",
       "      <th>number_of_comma</th>\n",
       "      <th>affin</th>\n",
       "      <th>blob</th>\n",
       "      <th>apple</th>\n",
       "      <th>google</th>\n",
       "      <th>twitter</th>\n",
       "      <th>microsoft</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forget the phone nice ui like the scroll featu...</td>\n",
       "      <td>google</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i hate when my phne do what it want on twitter</td>\n",
       "      <td>twitter</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and onli the first imag in my photo roll made ...</td>\n",
       "      <td>apple</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-0.056667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the lock screen now ha facial recognit capabl ...</td>\n",
       "      <td>google</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>teamgooglenexu rt b y googl samsung perfect ic...</td>\n",
       "      <td>google</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>karth vader when did you chang your nick again...</td>\n",
       "      <td>twitter</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>goodnight twitter</td>\n",
       "      <td>twitter</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>androidpolic duli note i hope aosp is updat wi...</td>\n",
       "      <td>google</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>microsoft s plan for bring it bi tool to io an...</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>yeah im gon twitter but fuck wit me</td>\n",
       "      <td>twitter</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2396 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               traintxt traintopic    trainY  \\\n",
       "0     forget the phone nice ui like the scroll featu...     google  positive   \n",
       "1       i hate when my phne do what it want on twitter     twitter   neutral   \n",
       "2     and onli the first imag in my photo roll made ...      apple  negative   \n",
       "3     the lock screen now ha facial recognit capabl ...     google   neutral   \n",
       "4     teamgooglenexu rt b y googl samsung perfect ic...     google   neutral   \n",
       "...                                                 ...        ...       ...   \n",
       "2391  karth vader when did you chang your nick again...    twitter   neutral   \n",
       "2392                                 goodnight twitter     twitter   neutral   \n",
       "2393  androidpolic duli note i hope aosp is updat wi...     google   neutral   \n",
       "2394  microsoft s plan for bring it bi tool to io an...  microsoft   neutral   \n",
       "2395               yeah im gon twitter but fuck wit me     twitter   neutral   \n",
       "\n",
       "      number_of_quote  number_of_stop  number_of_exclamation  \\\n",
       "0                 0.0              98                      0   \n",
       "1                 0.0              47                      0   \n",
       "2                 0.0             113                      0   \n",
       "3                 0.0              76                      1   \n",
       "4                 0.0              86                      0   \n",
       "...               ...             ...                    ...   \n",
       "2391              0.0             131                      0   \n",
       "2392              0.0              20                      0   \n",
       "2393              0.0              82                      0   \n",
       "2394              0.0             128                      0   \n",
       "2395              0.0              40                      0   \n",
       "\n",
       "      number_of_questionmark  number_of_hashtag  number_of_mention  \\\n",
       "0                          0                  3                  0   \n",
       "1                          0                  1                  0   \n",
       "2                          2                  0                  1   \n",
       "3                          0                  3                  0   \n",
       "4                          0                  5                  1   \n",
       "...                      ...                ...                ...   \n",
       "2391                       2                  1                  1   \n",
       "2392                       0                  1                  0   \n",
       "2393                       0                  2                  1   \n",
       "2394                       0                  2                  0   \n",
       "2395                       0                  1                  0   \n",
       "\n",
       "      number_of_comma  affin      blob  apple  google  twitter  microsoft  \\\n",
       "0                   0    4.0  0.600000      0       1        0          0   \n",
       "1                   0   -2.0 -0.800000      0       0        1          0   \n",
       "2                   2   -4.0 -0.056667      1       0        0          0   \n",
       "3                   0    3.0  0.000000      0       1        0          0   \n",
       "4                   0    3.0  1.000000      0       1        0          0   \n",
       "...               ...    ...       ...    ...     ...      ...        ...   \n",
       "2391                0   -3.0 -0.500000      0       0        1          0   \n",
       "2392                0    2.0  0.500000      0       0        1          0   \n",
       "2393                0    2.0  0.000000      0       1        0          0   \n",
       "2394                2    0.0  0.500000      0       0        0          1   \n",
       "2395                0   -3.0 -0.400000      0       0        1          0   \n",
       "\n",
       "      length  \n",
       "0         67  \n",
       "1         47  \n",
       "2         99  \n",
       "3         63  \n",
       "4         73  \n",
       "...      ...  \n",
       "2391     120  \n",
       "2392      18  \n",
       "2393      66  \n",
       "2394      82  \n",
       "2395      36  \n",
       "\n",
       "[2396 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ptint pre-processing results\n",
    "display(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Encoding\n",
    "\n",
    "### Use BoW representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "comp_vectorizer = CountVectorizer(max_features=3000, stop_words=\"english\")\n",
    "train_bow_features = comp_vectorizer.fit_transform(train_data[\"traintxt\"]).toarray()\n",
    "train_bow = pd.DataFrame(train_bow_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2990</th>\n",
       "      <th>2991</th>\n",
       "      <th>2992</th>\n",
       "      <th>2993</th>\n",
       "      <th>2994</th>\n",
       "      <th>2995</th>\n",
       "      <th>2996</th>\n",
       "      <th>2997</th>\n",
       "      <th>2998</th>\n",
       "      <th>2999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2396 rows × 3000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...  2990  \\\n",
       "0        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "2391     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2392     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2393     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2394     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2395     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "      2991  2992  2993  2994  2995  2996  2997  2998  2999  \n",
       "0        0     0     0     0     0     0     0     0     0  \n",
       "1        0     0     0     0     0     0     0     0     0  \n",
       "2        0     0     0     0     0     0     0     0     0  \n",
       "3        0     0     0     0     0     0     0     0     0  \n",
       "4        0     0     0     0     0     0     0     0     0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "2391     0     0     0     0     0     0     0     0     0  \n",
       "2392     0     0     0     0     0     0     0     0     0  \n",
       "2393     0     0     0     0     0     0     0     0     0  \n",
       "2394     0     0     0     0     0     0     0     0     0  \n",
       "2395     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[2396 rows x 3000 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =>  0.81875\n",
      "\n",
      "Random Forest Classifier results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.74      0.73        72\n",
      "     neutral       0.86      0.91      0.88       333\n",
      "    positive       0.71      0.49      0.58        75\n",
      "\n",
      "    accuracy                           0.82       480\n",
      "   macro avg       0.76      0.71      0.73       480\n",
      "weighted avg       0.81      0.82      0.81       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Consider class unbalanced\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "selected_features = ['number_of_exclamation', 'number_of_questionmark', 'number_of_hashtag',\n",
    "                     'number_of_quote', 'number_of_stop', 'number_of_mention',\n",
    "                     'affin', 'blob', 'apple', 'google', 'microsoft']\n",
    "\n",
    "train = pd.merge(train_bow, train_data[selected_features], left_index=True, right_index=True)\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(train, trainY, test_size=0.2)\n",
    "\n",
    "bow_rf_clf_model = RandomForestClassifier(n_estimators = 1000, min_samples_split = 10, bootstrap = True,\n",
    "                                          max_depth = 100, random_state = 0, class_weight='balanced')\n",
    "\n",
    "bow_rf_clf_model.fit(train_X, train_Y)\n",
    "pred_Y = bow_rf_clf_model.predict(test_X)\n",
    "\n",
    "print(\"Accuracy => \", accuracy_score(pred_Y, test_Y))\n",
    "print(\"\\nRandom Forest Classifier results:\")\n",
    "print(classification_report(test_Y, pred_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict data\n",
    "### Prediction of the best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testtxt\n",
    "c1 = np.array(testtxt)\n",
    "dix = {\"testtxt\": c1}\n",
    "test_data = pd.DataFrame(dix)\n",
    "\n",
    "add_extra_feature(test_data, test_data[\"testtxt\"])\n",
    "\n",
    "test_data['affin'] = test_data['testtxt'].apply(eva_afinn_score)\n",
    "test_data['blob'] = test_data['testtxt'].apply(eva_blob_score)\n",
    "test_data['traintxt'] = test_data['testtxt'].apply(clean_str)\n",
    "\n",
    "eva_comp(test_data, test_data[\"testtxt\"])\n",
    "test_data['length'] =  test_data[\"testtxt\"].apply(lambda x: (len(x)))\n",
    "\n",
    "test_data[\"testtxt\"] = test_data[\"testtxt\"].apply(tokenize)\n",
    "test_data[\"testtxt\"] = test_data[\"testtxt\"].apply(stemming)\n",
    "test_data[\"testtxt\"] = test_data[\"testtxt\"].apply(word_to_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bow_features = comp_vectorizer.transform(test_data[\"testtxt\"]).toarray()\n",
    "test_bow = pd.DataFrame(test_bow_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'neutral' 'neutral' ... 'neutral' 'neutral' 'neutral']\n",
      "1028\n"
     ]
    }
   ],
   "source": [
    "selected_features = ['number_of_exclamation', 'number_of_questionmark', 'number_of_hashtag',\n",
    "                     'number_of_quote', 'number_of_stop', 'number_of_mention',\n",
    "                     'affin', 'blob', 'apple', 'google', 'microsoft']\n",
    "\n",
    "test = pd.merge(test_bow, test_data[selected_features], left_index=True, right_index=True)\n",
    "pred_Y = bow_rf_clf_model.predict(test)\n",
    "\n",
    "print(pred_Y)\n",
    "print(len(pred_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv_kaggle_sub(\"my_submission.csv\", pred_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closing Remarks\n",
    "\n",
    "**The best performance my model can achieve is balanced RandomForest classifier + meta features + BoW (This combination actually surprise me). It gives me the following hints:**\n",
    "\n",
    "1. BoW can outperform TFIDF\n",
    "2. Data pre-processing and cleansing is very important\n",
    "3. Analyae the database before taking any actions\n",
    "4. Meta features are very helpful, try your best to make use of it\n",
    "5. The LSTM NN I trained above seems overfitted, it acts poor on the test data\n",
    "\n",
    "**Before doing this assignment, I alse found some useful blogs that verified my ideas:**\n",
    "1. How to use BERT and Google's word embedding: https://www.kaggle.com/gunesevitan/nlp-with-disaster-tweets-eda-cleaning-and-bert#6.-Cross-validation\n",
    "2. How to analyse your database: https://towardsdatascience.com/text-analysis-feature-engineering-with-nlp-502d6ea9225d\n",
    "3. Feature Engineering (meta feature extraction, fantastic): https://www.analyticsvidhya.com/blog/2021/04/a-guide-to-feature-engineering-in-nlp/\n",
    "4. How to analyse your database: https://www.analyticsvidhya.com/blog/2021/06/twitter-sentiment-analysis-a-nlp-use-case-for-beginners/\n",
    "\n",
    "**My special tricks summary:**\n",
    "1. Handle special emoji. For example, '&lt;3' is the HTML code for a heart and suggests positive sentiment\n",
    "2. Extract meta features in punctuations. It's intuitive that people will use '!!!', '....', '???' to express special sentiments\n",
    "3. Make use of public sentiment analysis tools like Afinn and TextBlob\n",
    "4. Be careful about the class unbalance will be really helpful (raise 2% acc)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
